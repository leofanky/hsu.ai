Theory of mind refers to humans' ability to represent the mental states of others, including their desires, beliefs, and intentions. The experiment propose to train a machine to build such models too. They design a Theory of Mind neural network, a ToMnet, which uses meta-learning to build models of the agents it encounters, from observations of their behavior alone. Through this process, it acquires a strong past model for agents' behavior and as the ability to predict about agents' characteristics and mental states using only a small number of observations of the behavior. We apply the ToMnet to agents behaving in simple grid-world environments, showing that it learns to model random, algorithmic, and deep reinforcement learning agents from varied populations, and that it passes classic Theory of Mind tasks like recognizing that others can hold false beliefs about the world. They argue that this system, which autonomously learns how to model other agents in its world, is an important step forward for developing multi-agent AI systems, for building intermediating technology for machine to human interaction, and for advancing the progress on interpretable AI code.
